{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDKWDWxuneisRw1vhvDObu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0AunAS7mqx",
        "colab_type": "text"
      },
      "source": [
        "1. Improving a model's performance by tuning it's parameters.\n",
        "2. Finding he values of the important parameters of a model(provide best generalization) is a tricky task, but necessary for almost all models and datasets.\n",
        "3. Because it is such a common task, there are standard methods in scikit learn to help us with it.\n",
        "4. The most commonly used method is the **Grid Search** method which means trying all possible combinations of the parameters interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1661Uqa8bSh",
        "colab_type": "text"
      },
      "source": [
        "* Consider the case of Kernel SVM with an RBF(radial basis function) kernel.\n",
        "* There are 2 important parameters: the kernel bandwidth, gamma, and the regularization parameter, C.\n",
        "* Say we want to try the values 0.001, 0.01, 0.1, 1, 10, 100 for the parameter C and same for gamma.\n",
        "* Because we have siz different setting for C and gamma that we want to try, we have 36 combinations of parameters in total."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6srNSfb7h2I",
        "colab_type": "text"
      },
      "source": [
        "## Simple Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzgsGQlg9a_Z",
        "colab_type": "text"
      },
      "source": [
        "* Implementing a simple grid search just as 'for' loops over the 2 parameters, training and evaluating a classifier for each combination.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4PIT6WB7czo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8030dbd7-848e-41ae-b32f-eb1c87d0f3b0"
      },
      "source": [
        "# Naive Grid Search Implementation\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
        "\n",
        "print(\"Size of training set: {} Size of testing set: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "  for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "\n",
        "    # For each combination of parameters, Train and SVC\n",
        "    svm = SVC(gamma=gamma, C=C)\n",
        "    svm.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the SVC on the test set\n",
        "    score = svm.score(X_test, y_test)\n",
        "\n",
        "    # If we get a better score, store the score and the parameters.\n",
        "    if score > best_score:\n",
        "      best_score = score\n",
        "      best_parametrs = {'C': C, 'gamma': gamma}\n",
        "\n",
        "print(\"Best Score: {:.2f}\".format(best_score))\n",
        "print(\"Best Parameters: {}\".format(best_parametrs))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: 112 Size of testing set: 38\n",
            "Best Score: 0.97\n",
            "Best Parameters: {'C': 100, 'gamma': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX3JOhsK_A6X",
        "colab_type": "text"
      },
      "source": [
        "### The Danger of Overfitting the Parameters and the Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3T5rJCa_N4P",
        "colab_type": "text"
      },
      "source": [
        "* Given the result, we will be tempted to report that we found a model with 97% accuracy on our dataset.\n",
        "* This claim would be overly optimistic(or just wrong), for the following reason:\n",
        "\n",
        "  1. We triend many different parameters and selected the one with best accuracy on the test set, but this accuracy won't neccessarily carry over the new data.\n",
        "  2. Because we used the test data to adjust the parameters, we can no longer use it to assess how good the model is.\n",
        "  3. This is the same reason why we need to split the data into training and test sets in the first place; we need an independent dataset to evaluate, one that was not used to create the model.\n",
        "\n",
        "* One way to resolve this problem is to split the data again, so we have three datasets: training set to build the model, the validation (or development) set to select the parameters of the model, and the test set to evaluate the performance of the selected parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIIlGQzp-rnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "2e356a30-fa43-4e6b-c644-26cf2d21e484"
      },
      "source": [
        "!pip install mglearn\n",
        "import mglearn\n",
        "\n",
        "mglearn.plots.plot_threefold_split()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mglearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/8aced26fce0b2ae82c3c87cd3b6105f38ca6d9d51704ecc44aa54473e6b9/mglearn-0.1.9.tar.gz (540kB)\n",
            "\r\u001b[K     |▋                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mglearn) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mglearn) (1.0.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from mglearn) (7.0.0)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.10.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from mglearn) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mglearn) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->mglearn) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mglearn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler->mglearn) (1.12.0)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=ce44c6dc7204a57fa89b36e978ea0d901813c5ec8867b7f62618bbe45d1fe6af\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/a6/ea/a6a3716233fa62fc561259b5cb1e28f79e9ff3592c0adac5f0\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNP4PtkBSn0",
        "colab_type": "text"
      },
      "source": [
        "1. After selecting the best parameters using the validation set, we can rebuild a model using the parameter settings we found, but now training on both the training data and the validation data. \n",
        "\n",
        "2. This way we can use as much data as possible to build our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvF5zJRzBOyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6666968d-d7c8-4c64-abfd-f5957ebeda8d"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Split the data into training + validation set and test set\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
        "\n",
        "# Splitting training+validation data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
        "\n",
        "print(\"Size of training set: {} Size of validation set: {}  Size of test set: {}\\n\".format(X_train.shape[0], X_valid.shape[0],\n",
        "                                                                                           X_test.shape[0]))\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "  for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "\n",
        "    # For each combination of parameters, Train and SVC\n",
        "    svm = SVC(gamma=gamma, C=C)\n",
        "    svm.fit(X_train, y_train)\n",
        "  \n",
        "    # Evaluate the SVC on the test set\n",
        "    score = svm.score(X_test, y_test)\n",
        "\n",
        "    # If we get a better score, store the score and the parameters.\n",
        "    if score > best_score:\n",
        "      best_score = score\n",
        "      best_parametrs = {'C': C, 'gamma': gamma}\n",
        "\n",
        "# Rebuild the model on the combined training and validation set, and evaluate on the test set\n",
        "svm = SVC(**best_parametrs)\n",
        "svm.fit(X_trainval, y_trainval)\n",
        "test_score = svm.score(X_test, y_test)\n",
        "print(\"Best score on Validation set: {:.2f}\".format(best_score))\n",
        "print(\"Best Parameters: \", best_parametrs)\n",
        "print(\"Test score with best parameters: {:.2f}\".format(test_score))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set: 84 Size of validation set: 28  Size of test set: 38\n",
            "\n",
            "Best score on Validation set: 0.97\n",
            "Best Parameters:  {'C': 100, 'gamma': 0.001}\n",
            "Test score with best parameters: 0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTC4PCDm9L5H",
        "colab_type": "text"
      },
      "source": [
        "1. The best score in this case is equal to the earlier score but mostly it is below the earlier score, because we use less data to train the model. (X_train is smaller now because we split our dataset twice.)\n",
        "\n",
        "2. But the test score which tells us how we generalize is also the same but mostly it is lower (92%). \n",
        "\n",
        "3. Distinction between the 3 sets is fundamentally important for applying machine learning methods in practice.\n",
        "\n",
        "4. Any choices made based on the test set accuracy \"leak\" information from the test set into the model.\n",
        "\n",
        "5. Therefore it is important to keep a seperate test set, which is only used for the final evaluation.\n",
        "\n",
        "6. **It is a good practice to do all exploratory analysis and model selection using the training and validation set, and reserve the testing set for the final evaluation, this is even true for exploratory visualization.**\n",
        "\n",
        "7. Evaluating more than one model on the test set and choosing the better of the 2 will result in an overly optimistic estimate of how accurate the model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1XBfHEa9Blf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}