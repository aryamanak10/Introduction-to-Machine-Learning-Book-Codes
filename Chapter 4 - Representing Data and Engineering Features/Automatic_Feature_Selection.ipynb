{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic Feature Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgK21vVoSdboVhS8skHlHY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ticFx-_peeyD",
        "colab_type": "text"
      },
      "source": [
        "## Automatic Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rs0f0ooea4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All the three methods discussed here are for supervised learning algorithm so they need a target for fitting. This means we need to\n",
        "# split the data set into training and test sets and fit the feature selection only on the training part of the data.\n",
        "\n",
        "# Automatic Feature Selection helps us to retain those feature which are the best for our model results. Instead of increasing the number\n",
        "# of features theey decrease it to optimal features using three different strategies"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_kKd9Fbfkwg",
        "colab_type": "text"
      },
      "source": [
        "### Univariate Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exvpl-egfjnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computing statistically significant relationship between feature and the target.\n",
        "# Features with highest confidence are selected.\n",
        "# In classification, this is knows as Analysis of Variance.\n",
        "# Key Property of this tests are that they are univarite, meaning each feature is considered individually.\n",
        "# A feature will be discarded if it is 'ONLY' informative when combined with other feature.\n",
        "\n",
        "# These test are often fast to compute and do not require building the model. They are also ccompletely independent of the model that \n",
        "# you might want to apply after the feature selection"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC5RTzI7hBtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To use univariate selection in scikit learn, you need to choose a test.\n",
        "\n",
        "# Classification - f_classif (default), Regression - f_regression and a method to discard the features based on the p-values determined\n",
        "# in the test.\n",
        "\n",
        "# All methods for discarding the parameters use a threshold to discard all features with too high p-values(which mean they are unlikely\n",
        "# to be related to the target)\n",
        "\n",
        "# These methods differ in how they compute this threshold, with the simplest being SelectKBest, which selects fixed number of K-features\n",
        "\n",
        "# SelectPercentile which select a fixed percentage of features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAa3zNaUjyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are adding some non-informative noise in the cancer dataset. We will then apply the feature selection and we expect it to identify\n",
        "# the features that are non-informative and remove them."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGjQXdVkFqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17da72c7-f89f-40aa-9afb-3f42b621e285"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Getting Deterministic Random Numbers\n",
        "rng = np.random.RandomState(42)\n",
        "noise = rng.normal(size=(len(cancer.data), 50))\n",
        "\n",
        "# Adding noise features to the data, First 30 features are from dataset and next 50 are noise\n",
        "X_w_noise = np.hstack([cancer.data, noise])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, random_state=0, test_size=0.5)\n",
        "\n",
        "# Using f_classif (the default) and SelectPercentile to select 50% of the features\n",
        "select = SelectPercentile(percentile=50)\n",
        "select.fit(X_train, y_train)\n",
        "\n",
        "# Tranforming the training set\n",
        "X_train_selected = select.transform(X_train)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"X_train_selected shape: {}\".format(X_train_selected.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (284, 80)\n",
            "X_train_selected shape: (284, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vQMrT7Zliox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c476b5ff-9b27-4e7a-d936-e0a1904d52f4"
      },
      "source": [
        "# As you can see the number of features were reduced from 80 to 40 which is by 50%. To get the features that have been selected we use\n",
        "# get_support method, which returns a Boolean Mask of the selected Features.\n",
        "\n",
        "mask = select.get_support()\n",
        "print(mask)\n",
        "\n",
        "# Visualizing the mask -- Black is True and White is False\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
        "plt.xlabel(\"Sample Index\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True False  True False\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True  True False False False  True False  True\n",
            " False False  True False False False False  True False False  True False\n",
            " False  True False  True False False False False False False  True False\n",
            "  True False False False False  True False  True False False False False\n",
            "  True  True False  True False False False False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Index')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOF8SMXrmFvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "592adbb7-7f57-4530-8a40-cc9656ece8ad"
      },
      "source": [
        "# As you can see most of the original features were retained and the noise features were removed but not all the original features were\n",
        "# retained. \n",
        "\n",
        "# Now we will compare the performance of Logisitic Regression on all the features against the selected features.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Transforming the test data\n",
        "X_test_selected = select.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print(\"Score with all features: {:.3f}\".format(lr.score(X_test, y_test)))\n",
        "\n",
        "lr.fit(X_train_selected, y_train)\n",
        "print(\"Score with selected features: {:.3f}\".format(lr.score(X_test_selected, y_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score with all features: 0.916\n",
            "Score with selected features: 0.919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU0-DPFHnLz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As you can see the score with only the selected features is higher than the one with all the features. Hence it was able to remove the \n",
        "# noise but during this procedure it also removed some of the original features.\n",
        "\n",
        "# UniVariate feature selection can still be very helpful if there is such a large number of features that building a model on them is \n",
        "# infeasible or if you suspect that many features are completely uninformative."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlBUTRGJwZ7n",
        "colab_type": "text"
      },
      "source": [
        "### Model-Based Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42vig92ZwfI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uses a supervised ML model to judge the importance of each feature, and keeps only the important ones.\n",
        "# The supervised model used for feature selection does not need to be the same model that is used for the final supervised modelling.\n",
        "# The feature selection model need to provide some measure of importance for each feature so that they can be ranked by this measure.\n",
        "\n",
        "# Decision Tree and its type models provide a feature_importances_ attribute which directly encodes the importance of each feature.\n",
        "# Linear model have coefficient which can also be used to capture feature importances by considering the absolute values.\n",
        "\n",
        "# In contrast to univariate selection, model based selection considers all features at once, so it can capture interactions(by model)."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlH1i1vkyGYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "select = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), threshold=\"median\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvJty01qyYu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The SelectFromModel class selects all the features that have an importance measure of the feature (as provided by the supervised model).\n",
        "# To get a comparable result with univariate F.S we used the median as a thresold so half of the feature will be selected.\n",
        "# This is quite complex model and much more powerful than using univariate tests."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBszrv1o8SGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43adb64d-0b59-40a4-dddf-af1d42ad2f4c"
      },
      "source": [
        "# Now we will actually fit the model.\n",
        "\n",
        "select.fit(X_train, y_train)\n",
        "X_train_l1 = select.transform(X_train)\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"X_train_l1 shape: {}\".format(X_train_l1.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (284, 80)\n",
            "X_train_l1 shape: (284, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8491KiA98lLw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "4fd23141-58d8-45a0-cabd-7967b20b1609"
      },
      "source": [
        "# Looking at the features that were selected using mask\n",
        "mask = select.get_support()\n",
        "\n",
        "# Visualizing the mask -- Black is True and White is False\n",
        "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
        "plt.xlabel(\"Sample Index\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Index')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTofz2KG88vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "82e62368-fb84-4312-ea1d-a84e6ef5d68c"
      },
      "source": [
        "# Some of the noise features were also selected. Now let's look at the performance.\n",
        "\n",
        "X_test_l1 = select.transform(X_test)\n",
        "score = LogisticRegression().fit(X_train_l1, y_train).score(X_test_l1, y_test)\n",
        "print(\"Test Score: {:.3f}\".format(score))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 0.930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5I3jvLp9cXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With some better feature selection we improoved our score from uni-variate F.S"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez3KnrAV-MZY",
        "colab_type": "text"
      },
      "source": [
        "### Iterative Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtS3YpW-Or7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this type of F.S, we use a series of models with varying number of features. There are 2 basic methods: starting with no features\n",
        "# and adding features one by one until some stopping criterion is reached OR starting with all features and removing features one by one\n",
        "# until some stopping criterion is reached. \n",
        "\n",
        "# Because a series of models are built this method is much more computationally expensive than the other methods. One particular method\n",
        "# of this kind is 'recursive feature elimination (RFE)' which starts with all the features, build a model and discards the least important\n",
        "# feature, and so on until only a prespecified number of features are left\n",
        "\n",
        "# For this to work, the model used for F.S needs to provide some way to determine feature importance, as was the case for the model based\n",
        "# selection."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qw6Rlib_bMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "59f23f05-5c85-4649-8546-e6fd8e1cbf94"
      },
      "source": [
        "# Here we will use RandomForestModel as we used earlier\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42), n_features_to_select=40)\n",
        "select.fit(X_train, y_train)\n",
        "\n",
        "# Visualizing the selected features using Mask\n",
        "mask = select.get_support()\n",
        "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
        "plt.xlabel(\"Sample Index\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Index')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo11px4VFYG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The F.S got better than Uni-Variate and Model-Based Selection but one feature was still missed. Running this code also takes\n",
        "# significantly longer than the other 2 models because a Random Forest is trained 40 times, once for each feature that is droped."
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEFvxISjF3J8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e4b8d470-6896-4c03-8f03-56b96dc6e68e"
      },
      "source": [
        "# Accuracy of LogisticRegression Model using RFE\n",
        "\n",
        "X_train_rfe = select.transform(X_train)\n",
        "X_test_rfe = select.transform(X_test)\n",
        "\n",
        "score = LogisticRegression(max_iter=1000).fit(X_train_rfe, y_train).score(X_test_rfe, y_test)\n",
        "print(\"Test Score: {:.3f}\".format(score))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Score: 0.951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2nmXEpsGNO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5fe95b1-ec0e-412d-c438-a37b63be638e"
      },
      "source": [
        "print(\"Test score: {:.3f}\".format(select.score(X_test, y_test)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey5ZUyonGjB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here the performance of the RandomForest used inside the RFE is the same as that achieved by training a logistic regression model on\n",
        "# top of the selected features. In other words, once we have selected the right features, the linear model performs as well as the \n",
        "# random forest."
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}