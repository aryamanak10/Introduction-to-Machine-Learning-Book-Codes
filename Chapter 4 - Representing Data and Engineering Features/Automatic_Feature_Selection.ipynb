{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic Feature Selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSJkf80UJTtd9q5dVxcyYY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ticFx-_peeyD",
        "colab_type": "text"
      },
      "source": [
        "## Automatic Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rs0f0ooea4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All the three methods discussed here are for supervised learning algorithm so they need a target for fitting. This means we need to\n",
        "# split the data set into training and test sets and fit the feature selection only on the training part of the data.\n",
        "\n",
        "# Automatic Feature Selection helps us to retain those feature which are the best for our model results. Instead of increasing the number\n",
        "# of features theey decrease it to optimal features using three different strategies"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_kKd9Fbfkwg",
        "colab_type": "text"
      },
      "source": [
        "### Univariate Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exvpl-egfjnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Computing statistically significant relationship between feature and the target.\n",
        "# Features with highest confidence are selected.\n",
        "# In classification, this is knows as Analysis of Variance.\n",
        "# Key Property of this tests are that they are univarite, meaning each feature is considered individually.\n",
        "# A feature will be discarded if it is 'ONLY' informative when combined with other feature.\n",
        "\n",
        "# These test are often fast to compute and do not require building the model. They are also ccompletely independent of the model that \n",
        "# you might want to apply after the feature selection"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC5RTzI7hBtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To use univariate selection in scikit learn, you need to choose a test.\n",
        "\n",
        "# Classification - f_classif (default), Regression - f_regression and a method to discard the features based on the p-values determined\n",
        "# in the test.\n",
        "\n",
        "# All methods for discarding the parameters use a threshold to discard all features with too high p-values(which mean they are unlikely\n",
        "# to be related to the target)\n",
        "\n",
        "# These methods differ in how they compute this threshold, with the simplest being SelectKBest, which selects fixed number of K-features\n",
        "\n",
        "# SelectPercentile which select a fixed percentage of features"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAa3zNaUjyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are adding some non-informative noise in the cancer dataset. We will then apply the feature selection and we expect it to identify\n",
        "# the features that are non-informative and remove them."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTGjQXdVkFqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17da72c7-f89f-40aa-9afb-3f42b621e285"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# Getting Deterministic Random Numbers\n",
        "rng = np.random.RandomState(42)\n",
        "noise = rng.normal(size=(len(cancer.data), 50))\n",
        "\n",
        "# Adding noise features to the data, First 30 features are from dataset and next 50 are noise\n",
        "X_w_noise = np.hstack([cancer.data, noise])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_w_noise, cancer.target, random_state=0, test_size=0.5)\n",
        "\n",
        "# Using f_classif (the default) and SelectPercentile to select 50% of the features\n",
        "select = SelectPercentile(percentile=50)\n",
        "select.fit(X_train, y_train)\n",
        "\n",
        "# Tranforming the training set\n",
        "X_train_selected = select.transform(X_train)\n",
        "\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"X_train_selected shape: {}\".format(X_train_selected.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (284, 80)\n",
            "X_train_selected shape: (284, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vQMrT7Zliox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c476b5ff-9b27-4e7a-d936-e0a1904d52f4"
      },
      "source": [
        "# As you can see the number of features were reduced from 80 to 40 which is by 50%. To get the features that have been selected we use\n",
        "# get_support method, which returns a Boolean Mask of the selected Features.\n",
        "\n",
        "mask = select.get_support()\n",
        "print(mask)\n",
        "\n",
        "# Visualizing the mask -- Black is True and White is False\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
        "plt.xlabel(\"Sample Index\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True  True  True  True  True  True  True  True  True False  True False\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True  True False False False  True False  True\n",
            " False False  True False False False False  True False False  True False\n",
            " False  True False  True False False False False False False  True False\n",
            "  True False False False False  True False  True False False False False\n",
            "  True  True False  True False False False False]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Sample Index')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOF8SMXrmFvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "592adbb7-7f57-4530-8a40-cc9656ece8ad"
      },
      "source": [
        "# As you can see most of the original features were retained and the noise features were removed but not all the original features were\n",
        "# retained. \n",
        "\n",
        "# Now we will compare the performance of Logisitic Regression on all the features against the selected features.\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Transforming the test data\n",
        "X_test_selected = select.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print(\"Score with all features: {:.3f}\".format(lr.score(X_test, y_test)))\n",
        "\n",
        "lr.fit(X_train_selected, y_train)\n",
        "print(\"Score with selected features: {:.3f}\".format(lr.score(X_test_selected, y_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score with all features: 0.916\n",
            "Score with selected features: 0.919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU0-DPFHnLz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As you can see the score with only the selected features is higher than the one with all the features. Hence it was able to remove the \n",
        "# noise but during this procedure it also removed some of the original features.\n",
        "\n",
        "# UniVariate feature selection can still be very helpful if there is such a large number of features that building a model on them is \n",
        "# infeasible or if you suspect that many features are completely uninformative."
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}